# Part 1:プログラミングとは（理論編）

Wikipedia の「プログラミング」の項目には、は次のように書かれている。

>コンピュータのプログラミング(英：Programming)とは、コンピュータプログラムを作成する事により、人間の意図した処理を行うようにコンピュータに指示を与える行為。まず、そのプログラムの目的、さらには「本当に解決したい問題は何なのか」ということについて十分な検討が必要である。

前半部分の説明はすんなりと入ってくるが、後半部分の説明はなかなか哲学的である。あなたは「本当に解決したい問題は何なのか」を理解していないことなど無いだろう･･･と思うかもしれないが、実は「本当に解決したい問題が何なのか」を理解しないまま開発が行われたシステムの例は山ほどある。特に開発規模が大きくなるにつれてこのリスクが高まる。

では一体全体なぜこのようなことが起こってしまうのだろうか？　どのようにすればこのリスクを低減できるだろうか？　それを理解するためには、少々回り道をしてしまうかもしれないが、このミスマッチ問題の歴史的背景について紐解いていくことにしたい。

## なぜプログラミングするのか？（目的）

これまた哲学的な問いかけで申し訳ないが、プログラミングを行う目的には次の３つがあると筆者は考える。

- 問題を解決するため
- 問題を理解するため
- プロセスを楽しむため

それぞれについて、もう少し深掘りしていこう。ただし、最後のものについては本講義で対象としないので、参考文献を読んで自分で考察してみて欲しい。

### 問題を解決するためのプログラミング

「問題を解決する」はプログラミングの最も主たる目的であろう。コンピュータという決められた手続きを高速かつ正確に処理できる機械を用いて、何らかの問題を自動的に間違いなく解決したいというのが最も大きなニーズであるからである。

その場合、「本当に解決したい問題」は自分の解決したいニーズに決まってるじゃないか･･･とそう思うかもしれないが、ところがどっこい、ここには大きな落とし穴が待っている場合が多い。

例えばこんな場合を考えてみよう。

いま、あなたは多くの手順が必要な複雑な作業をなんとか自動化したいと思っているとする。そして、そのためにプログラミングを行うべきだと考えていたとしよう。あなたの持っているニーズは「それぞれの手順を間違いなく、高速に実施すること」である。少なくともそれに異論はないだろう。

しかし、ちょっと待って欲しい。「本当に解決すべき問題」は、高速で間違いなくその処理をすることなのだろうか？　たとえば、そのプロセスの中には、もっと合理的に出来る手順とかは含まれていないだろうか？あるいは、そもそもそのような手続きが必要でない仕組みを作るということでは無いだろうか？　いわゆる合理化や最適化と呼ばれる範疇である。

真の意味でプログラミングを行うということは、単なる高速化を行うということではなく、その周辺の問題を俯瞰し、本来あるべきことはどういうことなのか？について考え、それをシステムとして落とし込んでいくという高度な作業であるのだ。ある意味、最も適切なゴールを見つける、あるいは定義する作業であるとも言える。

このような抽象度の高い作業を「設計」(Software Design)と呼び、それに従ってプログラミングする具体的な作業を「実装」(Implementation) と呼ぶ。そして一般的に、両者は別のスキルであるとされる。特に日本のソフトウェア業界では、「設計」をするのが偉い人（SE）で「実装」は下請けのプログラマーにやらせる･･･という風に捉えられている。だから日本のソフトウェア業界は欧米に負けるのだ。これは筆者の持論だが、間違っていないと自信はある。

本来、適切に実装出来るのは設計の意図をきちんと捉えられるからであり、逆に、適切な設計ができるのはコンピュータの仕組みや動作を実装レベルで理解できるからである。つまり、設計と実装は表裏一体、陰と陽の関係なのである。どっちが偉いとか、そんなことはなく、どちらも重要なのだ。

実際、過去の偉人はどちらも達人級なのである。有名どころだけでも、ビル・ゲイツ、セルゲイ・ブリン、ラリー・ペイジ、ジェフベゾス、マーク・ザッカーバーグ、など枚挙にいとまがない。偉大なデベロッパーは、設計も実装も、はたまた運用までも、何もかも全て対応できるフルスタック・エンジニアなのである。

このように、プログラミングとは本来は非常に対象とする範囲が広い概念であるのだが、なぜか「実装」部分、とりわけプログラムを書く作業だけを捉えられることが多い。実際には、ソフトウェア・エンジニアリング（Software Engineering) という言い方がもっともしっくりくるのではないだろうか。あるいは、コーディング（Coding) という言い方も最近は良くされる。

いずれにせよ、プログラミングとは「本当に解決したい問題は何なのか」を明らかにする作業でもあり、その具体的な方法をコンピュータが理解できる内容に適切に変換していく作業であると言える。

特に、問題を解決するためのプログラミングにおいては、いかに自分達が求めるゴールを適切に設定できるかが、そのプログラミングが成功するかどうかを決めると言っても過言ではない。


### 問題を理解するためのプログラミング

一方、最終結果に対するゴールを自分達で適切に設定できない場合もある。

たとえば、一つひとつの要素については十分理解できるが、それぞれが複雑に作業した場合、どのような挙動となるかが容易に予測出来ない問題などである。

このように、様々な要素が複雑に絡み合った場合、どのような結果を生み出すか簡単に予測できない事象など、問題自体を理解するためにプログラミングという手段は非常に有効である。これがまさしく、理論、実験に次ぐ「第三の科学」とも呼ばれるコンピュータ・シミュレーションの実施内容であり目的である。

私たちが取り扱う炉物理計算も、元はといえばこの部類に入ると言えるだろう。特にモンテカルロ計算はまさしくこの典型例である。そもそもモンテカルロ法とは、元々は中性子が物質中を動き回る様子を探るためにスタニスワフ・ウラムが考案し、ジョン・フォン・ノイマンにより命名された手法と言われている。

このように、取り扱いたい問題の概念モデルを作成し、それをコンピュータが取り合え使える数学的モデルや数値計算モデルに落とし込むという、モデリング＆シミュレーション (Modelling & Simulation)という考え方が広く一般的になってきている。

この際に、意図したとおりに動作するかを確認すること（検証）や、期待される結果が得られることを確認すること（妥当性確認）を適切に行うことが大変重要である。ただし、妥当性確認については、直接的に行えない場合が多い。というのも、そもそもよく分からない現象を理解するためにシミュレーションを行うのであって、予測が正しいかどうかを直接的に確かめることが出来ないのが普通だからである。例えば、シビアアクシデント・シミュレーションなどはその端的な例である。このような場合、小規模な体系や限られた条件下において妥当性確認をせざるをえない。しかしながら、大規模体系と小規模体系ではスケーリング則 (Scaling Law)が成り立たない場合が多く、また限定的な条件から一般化することの正当性を説明することも難しい場合が多いため、妥当性確認の実施方法や結果の解釈には細心の注意が必要である。

検証(Verification)と妥当性確認(Validation)は合わせて V&V と喚ばれ、シミュレーションやそれを実現するためのソフトウェアの信頼性を担保するために重要な役割を担っているが、本講義での範囲を大幅に超えてしまうため、これ以上の議論は割愛する。興味のある読者は「モデリング＆シミュレーション」「Verification & Validation」などでググってみて欲しい。


## どのようにプログラミングするのか？（手段）

プログラミングの目的が明確になったとして、実際にどのような方法でプログラミングを行えば良いのだろうか？

これを一言で伝えるのは極めて難しい問題だ。体系立てて伝えることは非常に難しく、どこから手をつければ良いのか困ってしまうからだ。

以下では、あまり整理された内容でなくなる可能性もあるが、筆者が持っている知識と経験をできるだけアウトプットすることを試みる。何度も読んでみて欲しい。

## オブジェクト指向のすすめ

筆者がオブジェクト指向という概念に出会ったのは、かれこれ20年以上も前のことである。Smalltalk や Object Pascal について書籍を通じて学んだが、実際のプログラミングを体験したのは C++ が初めてであった。（その後、後に MacOS X のベースとなった NeXTStep 上で Objective-C を体験）

当時、X68000 という SHARP製パソコンで稼働する Ko-Window System というウィンドウシステムがあった。(ちなみに、当時は高嶺の花であった UNIXワークステーション上で動作する、X-Window System を参考にして作られたものである。これと同じ世界観を楽しめるという意味で画期的だった Ko-Window は一部のマニアの間で大流行した）筆者は Ko-Window 上で動作するとあるアプリケーションをC言語で製作していたのだが、その先輩が C++ のクラスライブラリも作っていたので試しに使ってみた。するとどうだろう、これまで大変だったウィンドウや各コンポーネントの管理が劇的に簡単になったのだった。これは大変な衝撃であった。

これまでの考え方と180度異なると言っても過言では無いオブジェクト指向の考え方は、まさしくコロンブスの卵的な発想であった。そして、いったんオブジェクト指向の考え方に慣れ親しむと、これまでは一体全体どのようにしてプログラムを書いてきたのだろうか･･･？と思えてしまうほど、自然な考え方になってきたのであった。

これまでのプログラムの作り方は、たとえて言うならば、設計者は全知全能の神となる必要があった。細部のロジックや個々の変数、関数の定義やその副作用（関数戻り値以外の影響）について、事細かく把握しておく必要があったからである。しかし、オブジェクト指向ではプログラムを複数のコンポーネントに分割し、互いの内部情報は原則的に参照できない。その代わり、それぞれがメッセージをやりとりしながら協調して動作する。こうして、ボトムアップ的なアプローチと各階層における適切な抽象化により、全体システムとして把握することが容易になったのである。

実は、オブジェクト指向の概念は身の回りにたくさん見つけることが出来る。というよりは、オブジェクト指向の考え方自体が、世の中の構造をモデリングした結果であると言えるだろう。

たとえば、ゲームのなかのキャラクターを例に考えてみよう。ここでは、往年の名作であるドラゴンクエスト（通称ドラクエ）のスライムを例にあげてみる。ゲーム中にはたくさんのスライムが登場するが、それぞれの個体は異なる状態を持っている。ただし、スライムという種類は同じなので基本的な特性は同じだから、動作内容もひとくくりに定義できると便利だろう。

この定義全体のことをオブジェクト指向ではクラス(Class)と呼び、各個別の動作に関する関数定義のことをメソッド (Method)と呼ぶ。また、異なる状態を持つそれぞれの個体のことをインスタンス (Instance)やオブジェクト(Object)と呼んでいる。（オブジェクトという呼び方は、オブジェクト指向と紛らわしいので、以後はインスタンスで統一する）

それぞれのスライム・インスタンスは、保持する内容は異なるが、処理はすべて同じだ。たとえば、スライム・クラスにて、「生まれる」「移動する」「闘う」「防御する」「ダメージを受ける」「死ぬ」などの基本動作（メソッド）を定義しておけば、スライムインスタンスを生成（「生まれる」というメソッドを呼び出す）した後は、それぞれのメソッドを呼び出せば、期待される動作をするだろう。この時、メソッドを呼び出した方は、その内部動作がどのように実現されているかは関知しないという点が重要である。逆に言うと、それぞれのスライム・インスタンスの内部状態(インスタンス変数)は、外部からは見えないように隠蔽しておくべきである。もし外部から内部変数を確認したい場合は、それを取得するためのメソッド(getter メソッド）を準備するというのが基本的な考え方である。

内部変数を自由に参照できないなんて、なんてオブジェクト指向は面倒なんだ･･･と思ったのであれば、それは早計だ。この、メソッドのインターフェース（インプット、アウトプット、副作用）をきちんと定義・公開することによって、内部の状態や実現方法に依存することがなくなるのである。つまり、互いの独立性が高まることで、複雑な処理を行う大規模システムを高い保守性を維持したまま実現することが容易になる･･･というわけだ。

もし仮に、それぞれの状態についても明示的に把握・管理ができたとうしよう。そんなとき、一部のモジュールの内部状態の管理方法を変更する必要がでたとしたら･･･一体全体どうなるだろうか？　このようなことは、複数人が関わるプロジェクトでは簡単に起こり得ることだろう。うまく行けば、コンパイルが出来ないとか動作しないという、明らかなエラー状態を生み出すことができる。しかし一番厄介なのは、一見問題なく動いているように見えるが、特定の条件のときにエラーが起こるという、非常に再現性に乏しいバグが発生する場合なのだ。こんな状況のデバッグ作業は本当に大変だろう。想像するだけでもゾッとしてしまう。

こういった非オブジェクト指向なアプローチでは、管理すべき対象が増えれば増えるほど、内部構造が非常になれば複雑になるほど各パートの結合度が高まり、互いに影響を与える可能性が高くなってしまうのである。確かに、関数定義を行い、構造化プログラミングを適切に行うことで、ある程度の規模までであれば問題の発生を抑制することができるが、その分だけ管理コストは増加していく。筆者の体験で言うと、ソースコードが1万行を超える規模あたりから管理コストは飛躍的に高まっていくだろう。

他にも、オブジェクト指向アプローチにおいては、継承(inheritance) や多相性(Polymorphism) という重要な概念がある。どちらもオブジェクト指向のメリットを享受するためには避けて通れない内容であるが、時間の関係から本講義では取り扱わない。興味のある読者はオブジェクト指向プログラミングに関する書籍等を読んでみて欲しい。


## モデリングのすすめ

どんな世界でも、成功するものと失敗するものがある。偶然による場合もあるが、大抵の場合、それぞれにはそれなりの理由があるものだ。このため、成功する確率を高めるためには、過去に成功した事例を研究し、その中から成功に至った要因を分析し、それを再現すれば良い。この基本的な戦略によって実践されるのがモデリング (Modeling) であり、あらゆる分野で基本的なメソッドとして活用されている。

ソフトウェア開発においても、このモデリングが非常に有効である。ここでは、モデリングすべき大きな二つの概念を紹介しよう。


### デザインパターンとアンチパターン

前節において、プログラミングとは「本当に解決したい問題は何なのか」を明らかにする作業でもあり、その具体的な方法をコンピュータが理解できる内容に適切に変換していく作業であると述べた。

この作業については、構造化プログラミングといった基本的な考え方はあったが、それほど体系化されたものはなかった。その後、オブジェクト指向アプローチが一般的になるにつれて、成功するソフトウェア開発には一定のパターンがあることを見いだした人々がいた。彼らは、それを「デザインパターン」と呼び、ソフトウェア設計のノウハウを再利用しやすいようにカタログ化したのである。

もともと、「デザインパターン」は建築の世界での概念であったが、それがソフトウェア開発の世界に導入され、開発者間でのコミュニケーションの円滑化に寄与した。最初に提唱されたデザインパターンは23種類であったが、近年はそれ以外のパターンも提唱されている。ただし、それぞれのパターンについて熟知しないとプログラムが書けないかというと、まったくそういうことではない。実際、デザインパターンを知らなくても良いプログラムは書けるだろうが、知らず知らずのうちにこれらのパターンを再発明していることがある。結局は、みな同じようなところに考えが行き着くからだろう。

ソフトウェアのデザインパターンを学ぶことは、言ってみれば武道での型を学ぶようなものだ。確立されたパターンにはムダがなく、その効用も証明済みだ。だったら学ばない理由はないだろう。また、デザインパターンに対する共通認識を持つことで、開発者間のコミュニケーション・コストを下げるという副次的な効果もある。「よし、ここは Factory Method でいこう」といえば、それで全ては話が通ったりするからである。

一方、同じパターンでも「やってはいけないパターン」もたくさん存在していて、それらを総称してアンチパターンと呼んでいる。アンチパターンには、ソフトウェア設計・実装からプロジェクト・マネジメントまで、多種多様のアンチパターンが提唱されている。いわば、ソフトウェア開発の「失敗学」だ。これらを学んでおくことによって、将来のリスクを大幅に低減することができるが、意外にアンチパターンを積極的に学ぼうという人はいないようである。既に多くの書籍や論文、Webサイトでの解説もあるので、ぜひとも調べてみて欲しい。

## アジャイル開発

アジャイルソフトウェア開発 (agile software development)、あるいは単純にアジャイル開発という言葉は聞いたことがあるだろうか？　この概念を説明する前に、まずはその対局にあるウォーターフォール開発 (Waterfall development) について説明しよう。

これはコンピュータが発明されてから長らく使われてきた旧来の開発もであるであり、特に大規模プロジェクトではほぼ全てがこの開発モデルを採用していたといっても過言ではないだろう。ウォーターフォール開発モデルでは、プロジェクトの各段階は、要件定義→設計→実装→テスト→運用、といった具合にそれぞれのステージが明確に分離されている。このため、それぞれのステージが完了すると、基本的には前のステージには戻ることは容易ではない。このため、上流側の設計フェーズではあれやこれやと考える必要があり、非常に難しいため、いわゆる高級エンジニアがこれを担当する場合が多い。しかし、所詮は人間である。予見できないことなんて山ほどある。であるから、実装フェーズに入ってから、実は要件定義の段階で仮定が間違っていた（どっかーん）･･･なんて言うことも良くある（本当はあってはいけないのだが･･･）　もう既にプロジェクトは動いていてそれには対応出来ないので、「これは仕様です」とか「この問題を解決するための処理を追加」といった~~言い訳やとりあえずの火消し対策~~説明やパッチによるアップデートが延々と繰り返されるのである。

こういった反省から、1990年代後半から欧米を中心にアジャイル開発のムーブメントが顕著になり、やがて日本にもその勢いが伝わってきた。アジャイルソフトウェア開発モデルを一言で言うと、反復（イテレーション）という短い時間単位を採用して、PDCA (Plan-Do-Check-Action) を高速に回しながら開発を進めていく方法である。システム全体を一気に作り込むのではなく、機能単位で開発を進めていき、頻繁にリリースを行っていく。これにより、常に自分達が正しい位置にいるのか、そして正しい方向に向かっているのを確認でき、プロジェクトが失敗するリスクを大幅に低減することができる。現在では、殆どの開発現場でアジャイル開発モデルは採用されている。また、アジャイルの考え方を運用面にまで展開した DevOps (Development & Operation) というモデルに発展している。（興味のある読者はぜひ調べて欲しい）

話をアジャイル開発に戻そう。最も有名な手法は、ケント・ベックらにより提唱されたエクストリーム・プログラミング (XP: Extreme Programming)だろう。 XP は小規模・精鋭の開発チームで実践した際に非常に高いパフォーマンスを発揮する方法で、5つの価値と19の具体的なプラクティス（実践）が定義されている。ドキュメントよりもソースコードを重視し、組織的開発の歯車となることよりも個人の責任と勇気を重んじる人間中心の開発プロセスであるとしている。

XP で定義されている開発のプラクティスについては、Wikipedia の解説が良くまとまっているので~~パクって~~引用し、筆者の経験に基づく解説を付記しておく。（少なからず個人的なバイアスが入っているのでその点は考慮して読んでいただきたい。）

#### テスト駆動型開発 (TDD: Test-Driven Development)
>実装を行うより先に、テストを作成する。実装は、そのテストをパスすることを目標に行う。テストを先に作成することで、求める機能が明確化され、シンプルな設計が可能になる。なお、このテストは、部品単位での正確性を確認するユニットテスト（ホワイトボックステスト）と、全体が顧客の要求を満たしているかを確認する受け入れテスト（ブラックボックステスト）の観点で作成する。テストは、自動テストであることが推奨される。なぜなら、それによって、コードの共同所有、リファクタリング、頻繁な結合が可能になるため[2]、開発が進んでも変更コストの増大を抑制することができる。

最初に TDDの概念を知ったときに、「最初にテストコードを書くなんて、それはないわ～。テストコード書くの面倒やし（笑）」と正直思った。でも新しい概念を知ったら、やっぱり試してみたいものである。で、試しにやってみたら、これが意外に楽しかった。そう、テストが楽しかったのである。こんな感覚は、この時が初めてであった。

なんと言っても、テストが通る瞬間はやっぱり快感だ。テストに成功した瞬間、エクスタシーを感じてドーパミンが激しく分泌される。この快感をもっと得ようと、さらにテストを書いていった。そして、次の快感を得るために、本体を実装していく･･･。こんな風に書くとヤバイ人のように思うかもしれないが、この正のフィードバックは想像していた以上に上手く機能したのである。

本講義でも TDD を実践していく。もしあなたがエクスタシーを感じられたのなら、開発者としての素養は十二分にあるだろう。


#### ペア・プログラミング
>プログラミングは、二人一組で行う。一人がコードを書き、もう一人はそれをチェックしながら、仕様書を確認したり全体構造を考えたりするなど、ナビゲートを行う。二人は、この役割を定期的に交代しながら仕事を進める。ナビゲータのサポートにより、以下の効果が得られる。
>- 細々とした問題の解決に要する時間が短くなる。
>- 常にコードレビューを行うことができる
>- 集中力が持続する。
>- コードの詳細を理解したメンバーが常に2人以上いることで後々のコード共有に役立つ。

ペアプログラミングの概念も初めて知ったとき、「そんなんしたら開発効率が劇下がりと違う？」と思った。浅はかだった･･･。

実際には、ペアプロは良いことづくめだ。だが、これを本気で実践すれば、非常に疲れる。一日やれば、夕方には疲労困憊･･･といった感じなのである。というのも、横にレビュアーが常にいるわけだから、自分が書くコードに対して常に説明できる状態を維持しなければならない。要するに、いい加減なことが出来ないのだ。これをするためには、常に集中力が高い状態を維持しないといけないため、どうやっても90分が限界だ。途中で休憩を入れたり役割を交代したりして、一日に数セットやれば本当にクタクタになってしまう。

生産性が劇的に上がるペアプロであるが、大きな欠点が二つある。一つは、**自分達は真剣に開発をおこなっているのに、わいわいと楽しそうに、なんだか遊んでいるように見える**という点だ。もう一つは、**開発コストを単純な人工数でのみ管理仕様とする傾向がある**からだ。本来、トータルコストは 人工数÷品質 に比例するものだ。したがって、品質を高めることによりトータルコストを下げることができるのだが、多くの場合はこういった発想が希薄である。これらが日本の開発現場でペアプロが実践されない（実践できない）理由なのでは無いだろうか。筆者の経験では、ペアプロを適切に実践することで確実にコードの品質は向上し、技術共有も促進される。特にベテランと新人を組み合わせたペアプロは有効であり、いま叫ばれている技術伝承の問題も一挙に解決できるだろう。あなたが開発現場の担当レベルであれば、ペアプロの実践を上申してみよう。リーダー的立場であれば、ぜひとも現場での実践を促して欲しい。

#### ソースコードの共有
>誰が作ったソースコードであっても、開発チーム全員が断りなく修正を行うことができる。ただし、全てのコードに対する責任を、全員が担う。

ソースコードを共有するためには、いわゆるリポジトリ管理が必要となる。この手段としては古くは RCS (Revision Control System)や SVN (Subversion) が使われたが、これから使うのであれば Git であろう。オープンソースの世界では、Git によるリポジトリ共有サービスである Github による公開・共有は、もはやデファクトスタンダードと言っても過言では無いだろう。Github が発明した "Pull request"により、他人のリポジトリに対して改善提案を簡単に行うことが出来るようになり、集合知としての開発スキームが格段に促進されるようになった。学術目的で開発するプロジェクトで、Github にてソースコードを公開している場合もある。特に炉物理分野においては、米国 MIT が積極的であり、OpenMC (https://github.com/mit-crpg/openmc) や OpenMOC (https://github.com/mit-crpg/OpenMOC) が Github にて公開されている。

複数人で開発しない、いわゆる一人プロジェクトにおいても、リポジトリ管理システムを用いることのメリットは多数ある。というより、リポジトリ管理システムを使用しないとまともに開発はできないだろう。プログラムをリポジトリに登録（コミット）しておけば、任意のタイミングでその状態を復元できるようになる。コミット時のログも見られるし、任意のリビジョン間の差分も簡単に確認できる。さらに、リビジョン・ツリーを分岐させて（ブランチ）たり、統合（マージ）したりと、自由自在に管理できるので、これを使わない手はない。また、「将来の自分は他人である」というポリシーのもと、適切に情報管理を行うことによって、「あれって、どうだったっけ？」という疑問に対しても適切に対処できるようになるだろう。

もし、リポジトリ管理システムを用いないのであれば、バージョン管理は非常に煩雑になるだろう。同じようなソースコードを含んだフォルダが大量に作られて、何がどう違うのか？を適切に管理できなくなり、早期に破綻することだろう。経験者が語るのであるから間違いは無い。

リポジトリ管理システム（特に Git 及び Github）に関する学習学は、決して損しない投資だと言えるため、是非ともやっておくべきである。


#### リファクタリング
>完成済みのコードでも、随時、改善処置を行う。この際、外部から見た動作は変更させずに、内部構造がより見通し良く優れたものになるようにする。テストが作成されていることが前提になる。

リファクタリングは、re-factor-ing というスペルからも分かるように、ソースコードの中から共通する因子 (factor) をくくりだし、まとめる作業である。たとえば、処理Ａのコードが既に実装済みの場合を考える。そこに処理Ｂを実装する際、処理Ａの内容とかなり似通っている場合、経験の浅い開発者は、処理Ａのコードをコピペ（筆者はこの言葉が大嫌いだ）後に、処理Ｂの目的に合うように変更する･･･といったことをしがちである。その結果、オリジナルである処理Ａのクローンのようなコードが大量に存在することになる。しかし、これはアンチパターンの最たるものだ。

もし、処理Ａの実装に問題があったとしたどうだろうか？　問題が発覚して対応を求められた開発者が経緯を知らない（もしくは忘れてしまっていた）場合、まずは処理Ａを修正するだろうが、似通った問題が残っていないかをどこまで調べるだろうか？　不幸にも処理Ｂが処理Ａと全く違う場所（モジュール等）で実装されていれば、問題があるであろう処理Ｂの存在に気づくことは非常に難しい。そして、マーフィーの法則によって、処理Ｂの問題が噴出するのである。これが安全に関わる内容、たとえばロケット、自動車、医療機器などの制御だったとしたら･･･考えただけでも恐ろしい。

であるので、コピペ（何度も言うが筆者はこの言葉が大嫌いだ）をするのでは無く、処理Ａと処理Ｂの共通因子を処理Ｃとして新たに定義してやり、処理Ａや処理Ｂから呼び出すようにすればよい。これがリファクタリングの根本的な考え方である。

また、オブジェクト指向プログラミングの場合、重要なことはオブジェクト間のインターフェースであるので、メソッドの内部実装は基本的には外部から隠蔽されている。その点で、上記のように共通因子で括るという意外にも、より効率的なコードや可読性の高いコードに変更するといったことも、広義のリファクタリングとして捉えられている。

#### YAGNI
>You Aren't Going to Need It.（必要なことだけ行う）。先を見据えて、前払い的に機能を増やし、実装を複雑化させることは避ける。むしろ無駄な機能があれば削りとり、今必要な機能だけのシンプルな実装に留めておく。これにより、後のイレギュラーな変更に対応しやすいようにする。シンプルで洗練され、安定性の高い機能・コードのまま、同時に将来的な汎用性も高めることは問題ないが、把握を難しくし、不安定化を招く機能・コードは、可能な限り削り落とす。

要するに、「今必要なものに集中しろ」ということだ。システム開発においては、「あれもいるし、これもいる。やっぱり、そっちもだ」といった具合に、さいしょから大風呂敷を敷きがちである。もちろん、将来的な構想について見通しておく必要はあるが、**今すぐ必要でないものに対して機能に対してあれこれ心配しても仕方が無い**のである。それよりも、いま必要なもにに集中し、可能な限り問題をシンプルにした方がよっぽど良い。

このような考え方は、何もソフトウェア開発が最初ではない。いろんなところで実践されていて、要するに呼び方が違うだけだ。トヨタ生産方式では「Just in time」と思想のもとで、カンバン方式により「必要なものを、必要な時に、必要な量だけ生産する」という管理がなされてきた。また、リーン開発手法では「実用最小限の製品(MVP: Minimum Valuable Product)」という形で表現されている。

なお、筆者は検証や問題解決の際に「最小問題セット」を取り扱うことを心掛けているが、このプラクティスの派生版と言えるだろう。


## その他のベストプラクティス
他にもいろんなベストプラクティスがあり、枚挙にいとまが無い。あまたあるプラクティスから、筆者が特に重要視しているものを幾つか挙げておこう。例のごとく Wikipedia等から~~パクって~~引用しておく。


#### KISSの原則 (KISS principle)

>KISS の原則 (KISS principle) とは、"Keep it simple, stupid" （シンプルにしておけ！この間抜け）、もしくは、"Keep it short and simple" （簡潔に単純にしておけ）という経験的な原則[1]の略語。その意味するところは、設計の単純性（簡潔性）は成功への鍵だということと、不必要な複雑性は避けるべきだということである。
>(Wikipediaより引用)

筆者は学生や新人のころ、恩師や先輩から「出来るだけシンプルに考えるということが大切」「作ったコードが正しいか手計算と比較してチェックすべし！」と教わった。言ってみればこれも KISSの原則に照らし合わせた原理原則である。

少し脱線するが、物事を分類する際には、「容易か困難か」という軸と「単純か複雑か」という軸で整理すると分かりやすい。

 
| (1) Easy & Simple  | (2) Easy & Complex  |
|:---|:---|
| **(3) Difficult & Simple**  | **(4) Difficult & Complex**  |


最も優先すべきは(1)を選択する戦略だろう。この次に選択すべきは(2)もしくは(3)であるが、これは目的と場合に応じて変わってくるだろう。(4)を選択しなくてはならない場合でも直接的に(4)を目指すのでは無く、(2)か(3)を経由することによって成功する確率は高められるので、このことは十分に意識しておきたい。


#### 車輪の再発明をしない

>車輪の再発明（しゃりんのさいはつめい、英: reinventing the wheel）は、車輪を題材にした慣用句であり、世界中で使われている。「広く受け入れられ確立されている技術や解決法を知らずに（または意図的に無視して）、同様のものを再び一から作ること」を意味する。
>(Wikipedia より引用)

ソフトウェア開発における「車輪」とは、主に既に開発されているアルゴリズムやソフトウェア群（ライブラリ）のことを指している。たとえば、固有値問題を解くためのソルバーを開発しようとしていたときに、既にその目的に合致したものがあればそれを使った方が効率的だ。もちろん、経験値を上げるために、敢えて車輪を再発明することも時には必要だ。学校などでの教育はその好例だ。

しかしながら、大抵の場合、特にプロダクション・システムを開発する場合は、既に効果が実証されている既存のライブラリを上手く活用することがとても重要だ。というのも、それらを適切に用いることで、製品の品質向上と開発コストの低減を実現できる可能性が格段に高まるからである。したがって、実際の開発行う際、目的に合致したライブラリが既に存在しないか、十分にサーベイをしておくことが望ましい。まだインターネットが発達していなかった頃はライブラリの公開も一般的で無く、また検索エンジンも発達していなかったため、サーベイ自体も非常に難しかった。しかしながら、ライブラリ公開の仕組み(Python における pip 等のパッケージ管理システム)や github.com 等のリポジトリ共有サービスにより、格段に簡単になっている。さらに、検索エンジンも高度に発達しているため、まずは徹底的に検索してみることを推奨する。

#### 名前重要

プログラミング言語 Ruby の作者である Matz こと、まつもとゆきひろ氏は以下のように述べている。

>適切な名前をつけられると言うことは、その機能が正しく理解されて、設計されているということで、逆にふさわしい名前がつけられないということは、その機能が果たすべき役割を設計者自身も十分理解できていないということなのではないでしょうか。個人的には適切な名前をつけることができた機能については、その設計の8割が完成したと考えても言い過ぎでないことが多いように思います。
(https://プログラマが知るべき97のこと.com/%e3%82%a8%e3%83%83%e3%82%bb%e3%82%a4/%e5%90%8d%e5%89%8d%e9%87%8d%e8%a6%81/　より引用)

「人は見た目が9割」というヒット本があったが、同様に、「プログラムは名前が9割」と言っても過言ではないだろう。クラス名、変数名、メソッド名、はたまたプロジェクト名など、理想的にはその名前から目的・役割・機能が直感的に理解出来るということが望ましい。いや、望ましいどころではない。**そうなるように名前をつける必要がある**のだ。

一つアンチパターンを紹介しよう。それは、実際の処理内容や目的と異なる名前を関数やメソッドにつけるというものだ。（実際にやったらアカンよ）　たとえば、store_data という名前の関数があったとしよう。この名前から「データを格納する」という機能が想起されるが、実際にはデータを削除するという機能をその関数が持っていたとしたらどうだろうか？　まさしくカオスであり、何を信じたら良いか全く分からなくなる･･･。

読者は「そんなばかげたことはしないだろう･･･」と思うかもしれない。実際にここまで酷い例は無いかもしれないが、たとえば "func1" といった関数名とか、"data1" といった変数名とか見たことはないだろうか？　**この関数・変数はいったい何のために存在するのか？** と疑問に思ったことはないだろうか？もしそんな経験があるとしたら、それはアンチパターンを発見したということで、自分は絶対にそのようなことはしない！と深く心に刻み込んでおいて欲しい。（特に、本講義の Part2 で見つけた場合はね･･･)

要するに、**それだけでその存在意義や機能が分かるように名前をつける** ことが大切だということだ。そのためには名前が長くなっても良いのだ。特に最近では、統合開発環境 (IDE: Integrated Development Environment) や高機能エディタが名前の補完機能を有しているため、長い名前でも全く問題なく使えるようになった。ものには限度というものはあるが、やはり適切な名前をつけることを心掛けたい。名前付けのセンスでその開発者の力量が計り知れる･･･という説もあるが、案外、的を外してはいないのかもしれない。


#### DRY (Don't Repat Yourself) 原則

DRY原則は、Andy HuntとDave Thomasが、著書「達人プログラマ」の中で提唱した原則で、プログラミングに関して守るべきとされている原則の中でも特に重要なものと言っていいだろう。 (https://プログラマが知るべき97のこと.com/%E3%82%A8%E3%83%83%E3%82%BB%E3%82%A4/DRY%E5%8E%9F%E5%89%87/)


なかなか一言で伝えるのが難しい概念だが、 IT用語辞典 e-Words の解説が端的に表現していると思うので、~~パク（もうええって）~~ 引用しておこう。

>DRY原則とは、情報システムの構成や構築手法についての原則の一つで、同じ意味や機能を持つ情報やデータを複数の場所に重複して置くことをなるべく避けるべきとする考え方。
>
>システムやソフトウェアを構成する設定や設計に関する情報について述べたもので、複数の場所に同じ情報が置かれていると変更時に整合性が取れなくなる危険性が高まるため、一箇所で管理して必ずそこから参照するようにすべきとする原則である。
>
>転じて、プログラムコード中で同じ(ような)動作をするコードを何度も書かずに、一度書いたものを再利用するようにすべきとする意味で用いられることもあるが、こちらは本来は“Once and Only Once”(OAOO)原則と呼ばれるものである。
>(IT用語辞典 e-Words より引用）


良く OAOO との混同される概念だが、提唱者である Dave Thomas は以下のように語っている。(https://www.artima.com/intv/dry.html)

>Dave Thomas:
 Most people take DRY to mean you shouldn't duplicate code. That's not its intention. The idea behind DRY is far grander than that.
 DRY says that every piece of system knowledge should have one authoritative, unambiguous representation. Every piece of knowledge in the development of something should have a single representation. A system's knowledge is far broader than just its code. It refers to database schemas, test plans, the build system, even documentation.
>
 >Given all this knowledge, why should you find one way to represent each feature? The obvious answer is, if you have more than one way to express the same thing, at some point the two or three different representations will most likely fall out of step with each other. Even if they don't, you're guaranteeing yourself the headache of maintaining them in parallel whenever a change occurs. And change will occur. DRY is important if you want flexible and maintainable software. 
>
 >The problem is: how do you represent all these different pieces of knowledge only once? If it's just code, then you can obviously organize your code so you don't repeat things, with the help of methods and subroutines. But how do you handle things like database schemas? This is where you get into other techniques in the book, like using code generation tools, automatic build systems, and scripting languages. These let you have single, authoritative representations that then generate non-authoritative work products, like code or DDLs (data description languages). 
> 
> （以下、筆者による超訳）
 デーブ・トーマス：
 殆どの人は DRY をコードを重複させないことだと思っているけど、そういうことじゃ無いんだ。DRYの背景にあるアイデアはもっと大きいものなんだ。
 DRYでは、システムに関するすべての要素は、信頼できる明確な一つの形として表現さるべきなんだ。何かを開発しているとき、あらゆる要素について 、それぞれは一つだけの表現形式をとるべきだ。システムの要素ってのは、コードだけじゃなく、もっと広いもんなんだよ。データベースのスキーマ、テスト計画、ビルドシステム、さらにはドキュメントまで指すからね。
>
>そういう状況において、どうして各機能を表現する一つの方法を見つけないといけないのか？ それは明らかなんだけど、あるとき同じ内容を一つ以上の方式で表現できたとすると、二つも三つも異なる表現形式があったら、それぞれが違ったものになってしまうだろうね。たとえそうならなかったとしても、変更される度にそれぞれメンテナンスする必要があるから、頭痛に悩まされ続けることになるだろうね。でも大丈夫。柔軟で保守できるソフトウェアを望むなら、DRYは重要だね。
>
>いろいろと違っている全ての要素を、どのようにして一回だけで表現するのか？というのが問題なんだ。これがもしコードの話だけだったら、メソッドとかサブルーチンとかを使って、コードを整理して繰り返しを無くすことはできるよね。でもデータベーススキーマみたいな話だったらどうすれば良いのか？ これについては、コード生成ツールや自動ビルドシステム、スクリプト言語とか、この本での他のテクニックの範疇にはいってくる。これらを使えば、たった一つの信頼できる表現形式から、コードや DLL(データ記述言語）みたいな第一義的じゃ無い中間成果物を得ることもできるんだ。

最後の下りが理解しにくいかもしれないが、DRY原則を高度に実践していけば、もはやコードやデータベーススキーマ等も自動的に作成できるということを言っている。文中にの "authoritative" という単語は、「（開発者が決める）第一義的、根源的なもの、だから信頼できる」という意味で使われている。そして、上位の情報（メタ情報）を活用することによって「システムを作るシステム」を作ることも出来ると言っているのだ。この応用として「メタプログラミング」や「ドメイン固有言語 (Domain Specific Language)」が挙げらる。具体例は Web フレームワークである Ruby on Rails の中で数多く見つけることが出来るだろう。興味のある読者はさらに調べてみて欲しい。


#### 設定より規約 (Convention over Conviguration)
>設定より規約（せっていよりきやく、英: convention over configuration）とは、開発者の決定すべきことを減少させ、単純にするが柔軟性は失わせないというソフトウェア設計パラダイム。
>
>この言葉は本来、開発者が指定しなければならないのはアプリケーションの慣例に従わない点だけだ、ということを意味している。例えば、モデルの中にSaleというクラスがあれば、データベース中の対応する表の名前はデフォルトでsalesである。この規約から逸脱したときだけ、例えばその表を "products_sold" という名前にした場合だけ、その名前を使ったコードを書く必要が生じる。
>
>使用しているツールが実装した規約が開発者の望む動作と一致していれば、設定ファイルを書く必要もない。実装規約と望みの動作が違っている場合、必要な動作を設定しなければならない。
>(Wikipediaより引用)

ソフトウェアを設計する際には、運用時に柔軟性を持たせることが望まれる。そのために、システムでは設定ファイルを用意し、その中にシステム変数の値を設定出来る場合が多い。この考え方自体は有益なものであるし妥当だ。ただし、何でもかんでも設定ファイルの中で定義するようにしてしまうと、今度はその管理の方がとても大変になってくる。

そこで、データベースのテーブル名の命名則だったり、ディレクトリ構成だったり、基本的な部分は「規約」という形でルール化しておくのだ。これによってムダな周辺コードを削減でき、開発者は本来集中すべきロジック部分に注力することができる。ただ、なんでも間でも「規約」としてしまうと、後に混乱してしまうだろう。であるので、何らかの形で明文化してく方が良い。



## プログラム開発において考えておきたいこと

### プログラムのライフサイクル

### ソフトウェアの品質保証


### レバレッジ戦略


### 自己投資の重要性



## 参考文献



<div style="page-break-before:always"></div>