# Part 1:プログラミンとは（理論・マインド編）

Wikipedia の「プログラミング」の項目には、は次のように書かれている。

>コンピュータのプログラミング(英：Programming)とは、コンピュータプログラムを作成する事により、人間の意図した処理を行うようにコンピュータに指示を与える行為。まず、そのプログラムの目的、さらには「本当に解決したい問題は何なのか」ということについて十分な検討が必要である。

前半部分の説明はすんなりと入ってくるが、後半部分の説明はなかなか哲学的である。あなたは「本当に解決したい問題は何なのか」を理解していないことなど無いだろう･･･と思うかもしれないが、実は「本当に解決したい問題が何なのか」を理解しないまま開発が行われたシステムの例は山ほどある。特に開発規模が大きくなるにつれてこのリスクが高まる。

では一体全体なぜこのようなことが起こってしまうのだろうか？　どのようにすればこのリスクを低減できるだろうか？　それを理解するためには、少々回り道をしてしまうかもしれないが、このミスマッチ問題の歴史的背景について紐解いていくことにしたい。


## なぜプログラミングするのか？（目的）

これまた哲学的な問いかけで申し訳ないが、プログラミングを行う目的には次の３つがあると筆者は考える。

- 問題を解決するため
- 問題を理解するため
- プロセスを楽しむため

それぞれについて、もう少し深掘りしていこう。ただし、最後のものについては本講義で対象としないので、参考文献を読んで自分で考察してみて欲しい。

### 問題を解決するためのプログラミング

「問題を解決する」はプログラミングの最も主たる目的であろう。コンピュータという決められた手続きを高速かつ正確に処理できる機械を用いて、何らかの問題を自動的に間違いなく解決したいというのが最も大きなニーズであるからである。

その場合、「本当に解決したい問題」は自分の解決したいニーズに決まってるじゃないか･･･とそう思うかもしれないが、ところがどっこい、ここには大きな落とし穴が待っている場合が多い。

例えばこんな場合を考えてみよう。

いま、あなたは多くの手順が必要な複雑な作業をなんとか自動化したいと思っているとする。そして、そのためにプログラミングを行うべきだと考えていたとしよう。あなたの持っているニーズは「それぞれの手順を間違いなく、高速に実施すること」である。少なくともそれに異論はないだろう。

しかし、ちょっと待って欲しい。「本当に解決すべき問題」は、高速で間違いなくその処理をすることなのだろうか？　たとえば、そのプロセスの中には、もっと合理的に出来る手順とかは含まれていないだろうか？あるいは、そもそもそのような手続きが必要でない仕組みを作るということでは無いだろうか？　いわゆる合理化や最適化と呼ばれる範疇である。

真の意味でプログラミングを行うということは、単なる高速化を行うということではなく、その周辺の問題を俯瞰し、本来あるべきことはどういうことなのか？について考え、それをシステムとして落とし込んでいくという高度な作業であるのだ。ある意味、最も適切なゴールを見つける、あるいは定義する作業であるとも言える。

このような抽象度の高い作業を「設計」(Software Design)と呼び、それに従ってプログラミングする具体的な作業を「実装」(Implementation) と喚び、一般的には両者は別のスキルであるとされる。特に日本のソフトウェア業界では、「設計」をするのが偉い人（SE）で「実装」は下請けのプログラマーにやらせる･･･といった風潮がまかり通っている。だから日本のソフトウェア業界は欧米に負けるのだ。

本来、適切に実装出来るのは、設計の意図をきちんと捉えられるからこそであり、逆に、コンピュータの仕組みや動作を実装レベルで理解できるからこそ適切な設計が出来るのである。つまり、設計と実装は表裏一体、陰と陽の関係なのである。どっちが偉いとか、そんなことはなく、どちらも重要なのだ。

実際、過去の偉人はどちらも達人級で出来ている。有名どころだけでも、ビル・ゲイツ、セルゲイ・ブリン、ラリー・ペイジ、ジェフベゾス、マーク・ザッカーバーグ、など枚挙にいとまがない。偉大なデベロッパーは、設計も実装も何もかも全て自分でやれる人なのである。

このように、プログラミングとは本来は非常に対象とする範囲が広い概念であるのだが、なぜか「実装」部分、とりわけプログラムを書く作業だけを捉えられることが多い。実際には、ソフトウェア・エンジニアリング（Software Engineering) という言い方がもっともしっくりくるのではないだろうか。あるいは、コーディング（Coding) という言い方も最近は良くされる。

いずれにせよ、プログラミングとは「本当に解決したい問題は何なのか」を明らかにする作業でもあり、その具体的な方法をコンピュータが理解できる内容に適切に変換していく作業であると言える。

特に、問題を解決するためのプログラミングにおいては、いかに自分達が求めるゴールを適切に設定できるかが、そのプログラミングが成功するかどうかを決めると言っても過言ではない。


### 問題を理解するためのプログラミング

一方、最終結果に対するゴールを自分達で適切に設定できない場合もある。

たとえば、一つひとつの要素については十分理解できるが、それぞれが複雑に作業した場合、どのような挙動となるかが容易に予測出来ない問題などである。

このように、様々な要素が複雑に絡み合った場合、どのような結果を生み出すか簡単に予測できない事象など、問題自体を理解するためにプログラミングという手段は非常に有効である。これがまさしく、理論、実験に次ぐ「第三の科学」とも呼ばれるコンピュータ・シミュレーションの実施内容であり目的である。

私たちが取り扱う炉物理計算も、元はといえばこの部類に入ると言えるだろう。特にモンテカルロ計算はまさしくこの典型例である。そもそもモンテカルロ法とは、元々は中性子が物質中を動き回る様子を探るためにスタニスワフ・ウラムが考案し、ジョン・フォン・ノイマンにより命名された手法と言われている。

このように、取り扱いたい問題の概念モデルを作成し、それをコンピュータが取り合え使える数学的モデルや数値計算モデルに落とし込むという、モデリング＆シミュレーション (Modelling & Simulation)という考え方が広く一般的になってきている。

この際に、意図したとおりに動作するかを確認すること（検証）や、期待される結果が得られることを確認すること（妥当性確認）を適切に行うことが大変重要である。ただし、妥当性確認については、直接的に行えない場合が多い。というのも、そもそもよく分からない現象を理解するためにシミュレーションを行うのであって、予測が正しいかどうかを直接的に確かめることが出来ないのが普通だからである。例えば、シビアアクシデント・シミュレーションなどはその端的な例である。このような場合、小規模な体系や限られた条件下において妥当性確認をせざるをえない。しかしながら、大規模体系と小規模体系ではスケーリング則 (Scaling Law)が成り立たない場合が多く、また限定的な条件から一般化することの正当性を説明することも難しい場合が多いため、妥当性確認の実施方法や結果の解釈には細心の注意が必要である。

検証(Verification)と妥当性確認(Validation)は合わせて V&V と喚ばれ、シミュレーションやそれを実現するためのソフトウェアの信頼性を担保するために重要な役割を担っているが、本講義での範囲を大幅に超えてしまうため、これ以上の議論は割愛する。興味のある読者は「モデリング＆シミュレーション」「Verification & Validation」などでググってみて欲しい。


## どのようにプログラミングするのか？（手段）

プログラミングの目的が明確になったとして、実際にどのような方法でプログラミングを行えば良いのだろうか？

これを一言で伝えるのは極めて難しい問題だ。体系立てて伝えることは非常に難しく、どこから手をつければ良いのか困ってしまうからだ。

以下では、あまり整理された内容でなくなる可能性もあるが、筆者が持っている知識と経験をできるだけアウトプットすることを試みる。何度も読んでみて欲しい。

## オブジェクト指向のすすめ

筆者がオブジェクト指向という概念に出会ったのは、かれこれ20年以上も前のことである。Smalltalk や Object Pascal について書籍を通じて学んだが、実際のプログラミングを体験したのは C++ が初めてであった。（その後、後に MacOS X のベースとなった NeXTStep 上で Objective-C を体験）

当時、X68000 という SHARP製パソコンで稼働する Ko-Window System というウィンドウシステムがあった。(ちなみに、当時は高嶺の花であった UNIXワークステーション上で動作する、X-Window System を参考にして作られたものである。これと同じ世界観を楽しめるという意味で画期的だった Ko-Window は一部のマニアの間で大流行した）筆者は Ko-Window 上で動作するとあるアプリケーションをC言語で製作していたのだが、その先輩が C++ のクラスライブラリも作っていたので試しに使ってみた。するとどうだろう、これまで大変だったウィンドウや各コンポーネントの管理が劇的に簡単になったのだった。これは大変な衝撃であった。

これまでの考え方と180度異なると言っても過言では無いオブジェクト指向の考え方は、まさしくコロンブスの卵的な発想であった。そして、いったんオブジェクト指向の考え方に慣れ親しむと、これまでは一体全体どのようにしてプログラムを書いてきたのだろうか･･･？と思えてしまうほど、自然な考え方になってきたのであった。

これまでのプログラムの作り方は、たとえて言うならば、設計者は全知全能の神となる必要があった。細部のロジックや個々の変数、関数の定義やその副作用（関数戻り値以外の影響）について、事細かく把握しておく必要があったからである。しかし、オブジェクト指向ではプログラムを複数のコンポーネントに分割し、互いの内部情報は原則的に参照できない。その代わり、それぞれがメッセージをやりとりしながら協調して動作する。こうして、ボトムアップ的なアプローチと各階層における適切な抽象化により、全体システムとして把握することが容易になったのである。

実は、オブジェクト指向の概念は身の回りにたくさん見つけることが出来る。というよりは、オブジェクト指向の考え方自体が、世の中の構造をモデリングした結果であると言えるだろう。

たとえば、ゲームのなかのキャラクターを例に考えてみよう。ここでは、往年の名作であるドラゴンクエスト（通称ドラクエ）のスライムを例にあげてみる。ゲーム中にはたくさんのスライムが登場するが、それぞれの個体は異なる状態を持っている。ただし、スライムという種類は同じなので基本的な特性は同じだから、動作内容もひとくくりに定義できると便利だろう。

この定義全体のことをオブジェクト指向ではクラス(Class)と呼び、各個別の動作に関する関数定義のことをメソッド (Method)と呼ぶ。また、異なる状態を持つそれぞれの個体のことをインスタンス (Instance)やオブジェクト(Object)と呼んでいる。（オブジェクトという呼び方は、オブジェクト指向と紛らわしいので、以後はインスタンスで統一する）

それぞれのスライム・インスタンスは、保持する内容は異なるが、処理はすべて同じだ。たとえば、スライム・クラスにて、「生まれる」「移動する」「闘う」「防御する」「ダメージを受ける」「死ぬ」などの基本動作（メソッド）を定義しておけば、スライムインスタンスを生成（「生まれる」というメソッドを呼び出す）した後は、それぞれのメソッドを呼び出せば、期待される動作をするだろう。この時、メソッドを呼び出した方は、その内部動作がどのように実現されているかは関知しないという点が重要である。逆に言うと、それぞれのスライム・インスタンスの内部状態(インスタンス変数)は、外部からは見えないように隠蔽しておくべきである。もし外部から内部変数を確認したい場合は、それを取得するためのメソッド(getter メソッド）を準備するというのが基本的な考え方である。

内部変数を自由に参照できないなんて、なんてオブジェクト指向は面倒なんだ･･･と思ったのであれば、それは早計だ。この、メソッドのインターフェース（インプット、アウトプット、副作用）をきちんと定義・公開することによって、内部の状態や実現方法に依存することがなくなるのである。つまり、互いの独立性が高まることで、複雑な処理を行う大規模システムを高い保守性を維持したまま実現することが容易になる･･･というわけだ。

もし仮に、それぞれの状態についても明示的に把握・管理ができたとうしよう。そんなとき、一部のモジュールの内部状態の管理方法を変更する必要がでたとしたら･･･一体全体どうなるだろうか？　このようなことは、複数人が関わるプロジェクトでは簡単に起こり得ることだろう。うまく行けば、コンパイルが出来ないとか動作しないという、明らかなエラー状態を生み出すことができる。しかし一番厄介なのは、一見問題なく動いているように見えるが、特定の条件のときにエラーが起こるという、非常に再現性に乏しいバグが発生する場合なのだ。こんな状況のデバッグ作業は本当に大変だろう。想像するだけでもゾッとしてしまう。

こういった非オブジェクト指向なアプローチでは、管理すべき対象が増えれば増えるほど、内部構造が非常になれば複雑になるほど各パートの結合度が高まり、互いに影響を与える可能性が高くなってしまうのである。確かに、関数定義を行い、構造化プログラミングを適切に行うことで、ある程度の規模までであれば問題の発生を抑制することができるが、その分だけ管理コストは増加していく。筆者の体験で言うと、ソースコードが1万行を超える規模あたりから管理コストは飛躍的に高まっていくだろう。

他にも、オブジェクト指向アプローチにおいては、継承(inheritance) や多相性(Polymorphism) という重要な概念がある。どちらもオブジェクト指向のメリットを享受するためには避けて通れない内容であるが、時間の関係から本講義では取り扱わない。興味のある読者はオブジェクト指向プログラミングに関する書籍等を読んでみて欲しい。


## モデリングのすすめ

どんな世界でも、成功するものと失敗するものがある。偶然による場合もあるが、大抵の場合、それぞれにはそれなりの理由があるものだ。このため、成功する確率を高めるためには、過去に成功した事例を研究し、その中から成功に至った要因を分析し、それを再現すれば良い。この基本的な戦略によって実践されるのがモデリング (Modeling) であり、あらゆる分野で基本的なメソッドとして活用されている。

ソフトウェア開発においても、このモデリングが非常に有効である。ここでは、モデリングすべき大きな二つの概念を紹介しよう。


### デザインパターンとアンチパターン

前節において、プログラミングとは「本当に解決したい問題は何なのか」を明らかにする作業でもあり、その具体的な方法をコンピュータが理解できる内容に適切に変換していく作業であると述べた。

この作業については、構造化プログラミングといった基本的な考え方はあったが、それほど体系化されたものはなかった。その後、オブジェクト指向アプローチが一般的になるにつれて、成功するソフトウェア開発には一定のパターンがあることを見いだした人々がいた。彼らは、それを「デザインパターン」と呼び、ソフトウェア設計のノウハウを再利用しやすいようにカタログ化したのである。

もともと、「デザインパターン」は建築の世界での概念であったが、それがソフトウェア開発の世界に導入され、開発者間でのコミュニケーションの円滑化に寄与した。最初に提唱されたデザインパターンは23種類であったが、近年はそれ以外のパターンも提唱されている。ただし、それぞれのパターンについて熟知しないとプログラムが書けないかというと、まったくそういうことではない。実際、デザインパターンを知らなくても良いプログラムは書けるだろうが、知らず知らずのうちにこれらのパターンを再発明していることがある。結局は、みな同じようなところに考えが行き着くからだろう。

ソフトウェアのデザインパターンを学ぶことは、言ってみれば武道での型を学ぶようなものだ。確立されたパターンにはムダがなく、その効用も証明済みだ。だったら学ばない理由はないだろう。また、デザインパターンに対する共通認識を持つことで、開発者間のコミュニケーション・コストを下げるという副次的な効果もある。「よし、ここは Factory Method でいこう」といえば、それで全ては話が通ったりするからである。

一方、同じパターンでも「やってはいけないパターン」もたくさん存在していて、それらを総称してアンチパターンと呼んでいる。アンチパターンには、ソフトウェア設計・実装からプロジェクト・マネジメントまで、多種多様のアンチパターンが提唱されている。いわば、ソフトウェア開発の「失敗学」だ。これらを学んでおくことによって、将来のリスクを大幅に低減することができるが、意外にアンチパターンを積極的に学ぼうという人はいないようである。既に多くの書籍や論文、Webサイトでの解説もあるので、ぜひとも調べてみて欲しい。

## アジャイル開発

アジャイルソフトウェア開発 (agile software development)、あるいは単純にアジャイル開発という言葉は聞いたことがあるだろうか？　この概念を説明する前に、まずはその対局にあるウォーターフォール開発 (Waterfall development) について説明しよう。

これはコンピュータが発明されてから長らく使われてきた旧来の開発もであるであり、特に大規模プロジェクトではほぼ全てがこの開発モデルを採用していたといっても過言ではないだろう。ウォーターフォール開発モデルでは、プロジェクトの各段階は、要件定義→設計→実装→テスト→運用、といった具合にそれぞれのステージが明確に分離されている。このため、それぞれのステージが完了すると、基本的には前のステージには戻ることは容易ではない。このため、上流側の設計フェーズではあれやこれやと考える必要があり、非常に難しいため、いわゆる高級エンジニアがこれを担当する場合が多い。しかし、所詮は人間である。予見できないことなんて山ほどある。であるから、実装フェーズに入ってから、実は要件定義の段階で仮定が間違っていた（どっかーん）･･･なんて言うことも良くある（本当はあってはいけないのだが･･･）　もう既にプロジェクトは動いていてそれには対応出来ないので、「これは仕様にしておこう」とか「この事例を回避するために，とりあえずこの処理を追加しておこう」といった言い訳やパッチワークが横行してしまう。

こういった反省から、1990年代後半から欧米を中心にアジャイル開発のムーブメントが顕著になり、やがて日本にもその勢いが伝わってきた。アジャイルソフトウェア開発モデルを一言で言うと、反復（イテレーション）という短い時間単位を採用して、PDCAを高速に回しながら開発を進めていく方法である。システム全体を一気に作り込むのでは無く、機能単位で開発を進めていき、頻繁にリリースを行っていく。これにより、常に自分達が正しい位置にいるのか、そして正しい方向に向かっているのを確認でき、プロジェクトが失敗するリスクを大幅に低減することができる。現在では、殆どの開発現場でアジャイル開発モデルは採用されている。また、アジャイルの考え方を運用面にまで展開した DevOps (Development & Operation) というモデルに発展している。（興味のある読者はぜひ調べて欲しい）

話をアジャイル開発に戻そう。最も有名な手法は、ケント・ベックらにより提唱されたエクストリーム・プログラミング (XP: Extreme Programming)だろう。 XP は小規模・精鋭の開発チームで実践した際に非常に高いパフォーマンスを発揮する方法で、5つの価値と19の具体的なプラクティス（実践）が定義されている。ドキュメントよりもソースコードを重視し、組織的開発の歯車となることよりも個人の責任と勇気を重んじる人間中心の開発プロセスであるとしている。

XP で定義されている開発のプラクティスについては、Wikipedia の解説が良くまとまっているので~~パクって~~引用しておく。

#### テスト駆動型開発 (TDD: Test-Driven Development)
>実装を行うより先に、テストを作成する。実装は、そのテストをパスすることを目標に行う。テストを先に作成することで、求める機能が明確化され、シンプルな設計が可能になる。なお、このテストは、部品単位での正確性を確認するユニットテスト（ホワイトボックステスト）と、全体が顧客の要求を満たしているかを確認する受け入れテスト（ブラックボックステスト）の観点で作成する。テストは、自動テストであることが推奨される。なぜなら、それによって、コードの共同所有、リファクタリング、頻繁な結合が可能になるため[2]、開発が進んでも変更コストの増大を抑制することができる。

#### ペア・プログラミング
>プログラミングは、二人一組で行う。一人がコードを書き、もう一人はそれをチェックしながら、仕様書を確認したり全体構造を考えたりするなど、ナビゲートを行う。二人は、この役割を定期的に交代しながら仕事を進める。ナビゲータのサポートにより、以下の効果が得られる。
>- 細々とした問題の解決に要する時間が短くなる。
>- 常にコードレビューを行うことができる
>- 集中力が持続する。
>- コードの詳細を理解したメンバーが常に2人以上いることで後々のコード共有に役立つ。

#### ソースコードの共有
>誰が作ったソースコードであっても、開発チーム全員が断りなく修正を行うことができる。ただし、全てのコードに対する責任を、全員が担う。

#### リファクタリング
>完成済みのコードでも、随時、改善処置を行う。この際、外部から見た動作は変更させずに、内部構造がより見通し良く優れたものになるようにする。テストが作成されていることが前提になる。

#### YAGNI
>You Aren't Going to Need It.（必要なことだけ行う）。先を見据えて、前払い的に機能を増やし、実装を複雑化させることは避ける。むしろ無駄な機能があれば削りとり、今必要な機能だけのシンプルな実装に留めておく。これにより、後のイレギュラーな変更に対応しやすいようにする。シンプルで洗練され、安定性の高い機能・コードのまま、同時に将来的な汎用性も高めることは問題ないが、把握を難しくし、不安定化を招く機能・コードは、可能な限り削り落とす。


## その他のベストプラクティス
他にもいろんなベストプラクティスがあり、枚挙にいとまが無い。あまたあるプラクティスから、筆者が特に重要視しているものを幾つか挙げておこう。例のごとく Wikipediaから~~パクって~~引用しておく。


#### KISSの原則 (KISS principle)

>KISS の原則 (KISS principle) とは、"Keep it simple, stupid" （シンプルにしておけ！この間抜け）、もしくは、"Keep it short and simple" （簡潔に単純にしておけ）という経験的な原則[1]の略語。その意味するところは、設計の単純性（簡潔性）は成功への鍵だということと、不必要な複雑性は避けるべきだということである。

筆者は学生や新人のころ、恩師や先輩から「出来るだけシンプルに考えるということが大切」「作ったコードが正しいか手計算と比較してチェックすべし！」と教わった。言ってみればこれも KISSの原則に照らし合わせた原理原則である。

少し脱線するが、物事を分類する際には、「容易か困難か」という軸と「単純か複雑か」という軸で整理すると分かりやすい。

 
| (1) Easy & Simple  | (2) Easy & Complex  |
|:---|:---|
| **(3) Difficult & Simple**  | **(4) Difficult & Complex**  |


最も優先すべきは(1)を選択する戦略だろう。この次に選択すべきは(2)もしくは(3)であるが、これは目的と場合に応じて変わってくるだろう。(4)を選択しなくてはならない場合でも直接的に(4)を目指すのでは無く、(2)か(3)を経由することによって成功する確率は高められるので、このことは十分に意識しておきたい。


#### 車輪の再発明をしない

>車輪の再発明（しゃりんのさいはつめい、英: reinventing the wheel）は、車輪を題材にした慣用句であり、世界中で使われている。「広く受け入れられ確立されている技術や解決法を知らずに（または意図的に無視して）、同様のものを再び一から作ること」を意味する。



#### 名前重要

#### DRY (Don't Repat Yourself) 原則

#### 設定より規約 (Convention over Conviguration)



## ピットフォール

### プログラムのライフサイクル

### ソフトウェアの品質保証

### レバレッジ戦略

### 自己投資の重要性



## 参考文献
